{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pYs6LMEbNqoQ"
   },
   "source": [
    "# Door and Key Experiments in Curriculum Learning\n",
    "\n",
    "-------------------------------\n",
    "\n",
    "\n",
    "Salkey, Jayson\n",
    "\n",
    "26/07/2018\n",
    "\n",
    "-----------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ztQEQvnKh2t6"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qB0tQ4aiAaIu"
   },
   "source": [
    "### Import Useful Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YzYtxi8Wh5SJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import namedtuple\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NDhSYfSDcCC"
   },
   "source": [
    "### Set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ps5OnkPmDbMX"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "np.set_printoptions(precision=3, suppress=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A hallway world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hallway(object):\n",
    "\n",
    "  def __init__(self, goal_loc, tabular=True, vision_size=1, discount=0.98, noisy=False):\n",
    "    # -3: Key\n",
    "    # -2: Door\n",
    "    # -1: wall\n",
    "    # 0: empty, episode continues\n",
    "    # other: number indicates reward, episode will terminate\n",
    "    \n",
    "    self._wall = -1\n",
    "    self._door = -2\n",
    "    self._key = -3\n",
    "    \n",
    "    self._layout = np.array([\n",
    "        [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "        [-1,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0, -1, -1],\n",
    "        [-1,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0, -1, -1],\n",
    "        [-1,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1, -1,  0,  0,  0, -1, -1],\n",
    "        [-1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1],\n",
    "        [-1, -1,  0, -1,  0,  0, -1,  0,  0, -1,  0,  0,  0,  0,  0, -1, -1],\n",
    "        [-1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -2, -2, -2, -1, -1],\n",
    "        [-1,  0,  0,  0, -1, -1, -1,  0,  0, -1, -1, -1,  0,  0,  0, -1, -1],\n",
    "        [-1,  0,  0,  0, -1, -1, -1,  0,  0, -1, -1, -1,  0,  0,  0, -1, -1],\n",
    "        [-1,  0,  0,  0, -1, -1,  0,  0,  0,  0, -1, -1,  0,  0,  0, -1, -1],\n",
    "        [-1, -1, -1, -1, -1, -1,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1],\n",
    "        [-1, -1, -1, -1, -1, -1,  0,  0,  0,  0, -1, -1, -1, -1, -1, -1, -1],\n",
    "        [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1],\n",
    "      ])\n",
    "    \n",
    "    \n",
    "    \n",
    "    self._goals = set()\n",
    "    \n",
    "    for e in goal_loc:\n",
    "      self._layout[e[0],e[1]] = e[2]\n",
    "      self._goals.add(e[2])\n",
    "    \n",
    "    self.goal_loc_r = goal_loc[-1][0]\n",
    "    self.goal_loc_c = goal_loc[-1][1]\n",
    "    self._layout[self.goal_loc_r,self.goal_loc_c] = goal_loc[-1][2]\n",
    "    \n",
    "    #self._goal = value\n",
    "    \n",
    "    # row, col format\n",
    "    self._start_state = (11, 8)\n",
    "    self._state = self._start_state\n",
    "    self._number_of_states = np.prod(np.shape(self._layout))\n",
    "    self._noisy = noisy\n",
    "    self._tabular = tabular\n",
    "    self._vision_size = vision_size\n",
    "    self._discount = discount\n",
    "    self._distanceToGoal = None\n",
    "    \n",
    "    #self.distanceToGoal()\n",
    "  \n",
    "  def resetState(self):\n",
    "    self._state = self._start_state\n",
    "  \n",
    "  def distanceToGoal(self):\n",
    "    return np.prod(self._layout.shape)\n",
    "#     if self._distanceToGoal != None:\n",
    "#       return self._distanceToGoal\n",
    "#     else:\n",
    "#       #print self._layout.shape\n",
    "#       distances = []\n",
    "#       stack = []\n",
    "#       visited = set()\n",
    "#       stack.append((self._start_state[1], self._start_state[0], 0))\n",
    "#       while len(stack) != 0:\n",
    "#         #print len(stack)\n",
    "#         cur_row, cur_col, dist = stack.pop()\n",
    "#         if (cur_row, cur_col) in visited:\n",
    "#           continue\n",
    "#         visited.add((cur_row, cur_col))\n",
    "\n",
    "#         if cur_row == self.goal_loc_r and cur_col == self.goal_loc_c:\n",
    "#           distances.append(dist)\n",
    "\n",
    "#         if cur_row+1 < self._layout.shape[0] and self._layout[cur_row+1, cur_col] != self._wall:\n",
    "#           stack.append((cur_row+1, cur_col, dist+1))\n",
    "#         if cur_row-1 > -1 and self._layout[cur_row-1, cur_col] != self._wall:\n",
    "#           stack.append((cur_row-1, cur_col, dist+1))\n",
    "#         if cur_col+1 < self._layout.shape[1] and self._layout[cur_row, cur_col+1] != self._wall:\n",
    "#           stack.append((cur_row, cur_col+1, dist+1))\n",
    "#         if cur_col-1 > -1 and self._layout[cur_row, cur_col-1] != self._wall:\n",
    "#           stack.append((cur_row, cur_col-1, dist+1))\n",
    "\n",
    "#       self._distanceToGoal = np.max(np.array(distances))\n",
    "#       return self._distanceToGoal\n",
    "    \n",
    "  def handleDoor(self):\n",
    "    pass\n",
    "  \n",
    "  @property\n",
    "  def number_of_states(self):\n",
    "    return self._number_of_states\n",
    "    \n",
    "  def plot_grid(self, title=None):\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(self._layout != self._wall, interpolation=\"nearest\", cmap='pink')\n",
    "    ax = plt.gca()\n",
    "    ax.grid(0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    if title != None:\n",
    "      plt.title(title)\n",
    "    else:\n",
    "      plt.title(\"The Grid\")\n",
    "    plt.text(8, 11, r\"$\\mathbf{S}$\", ha='center', va='center')\n",
    "    \n",
    "    for e in self._goals:\n",
    "      if e > 0:\n",
    "        y = np.where(self._layout==e)[0]\n",
    "        x = np.where(self._layout==e)[1]\n",
    "        for i in range(y.shape[0]): \n",
    "          #print y[i], x[i]\n",
    "          plt.text(x[i], y[i], r\"$\\mathbf{G}$\", ha='center', va='center')\n",
    "      elif e < 0:\n",
    "        y = np.where(self._layout==e)[0]\n",
    "        x = np.where(self._layout==e)[1]\n",
    "        for i in range(y.shape[0]): \n",
    "          #print y[i], x[i]\n",
    "          plt.text(x[i], y[i], r\"$\\mathbf{K}$\", ha='center', va='center')\n",
    "      \n",
    "#     if self._goal > 0:\n",
    "#       goal_y, goal_x = np.where(self._layout==self._goal)\n",
    "#       plt.text(goal_x, goal_y, r\"$\\mathbf{G}$\", ha='center', va='center')\n",
    "#     else:\n",
    "#       key_y, key_x = np.where(self._layout==self._key)\n",
    "#       plt.text(key_x, key_y, r\"$\\mathbf{K}$\", ha='center', va='center')\n",
    "    y = np.where(self._layout==self._door)[0]\n",
    "    x = np.where(self._layout==self._door)[1]\n",
    "    for i in range(y.shape[0]): \n",
    "      #print y[i], x[i]\n",
    "      plt.text(x[i], y[i], r\"$\\mathbf{D}$\", ha='center', va='center')\n",
    "    \n",
    "    h, w = self._layout.shape\n",
    "    for y in range(h-1):\n",
    "      plt.plot([-0.5, w-0.5], [y+0.5, y+0.5], '-k', lw=2)\n",
    "    for x in range(w-1):\n",
    "      plt.plot([x+0.5, x+0.5], [-0.5, h-0.5], '-k', lw=2)\n",
    "#     plt.savefig('./'+title)\n",
    "#     plt.close()\n",
    "\n",
    "  def get_obs(self):\n",
    "    y, x = self._state\n",
    "    return self.get_obs_at(x, y)\n",
    "\n",
    "  def get_obs_at(self, x, y):\n",
    "    if self._tabular:\n",
    "      return y*self._layout.shape[1] + x\n",
    "    else:\n",
    "      v = self._vision_size\n",
    "      location = np.clip(-self._layout[y-v:y+v+1,x-v:x+v+1], 0, 1)\n",
    "      return location\n",
    "\n",
    "  def step(self, action, agent_inventory):\n",
    "    item = None\n",
    "    y, x = self._state\n",
    "        \n",
    "    if action == 0:  # up\n",
    "      new_state = (y - 1, x)\n",
    "    elif action == 1:  # right\n",
    "      new_state = (y, x + 1)\n",
    "    elif action == 2:  # down\n",
    "      new_state = (y + 1, x)\n",
    "    elif action == 3:  # left\n",
    "      new_state = (y, x - 1)\n",
    "    else:\n",
    "      raise ValueError(\"Invalid action: {} is not 0, 1, 2, or 3.\".format(action))\n",
    "\n",
    "    new_y, new_x = new_state\n",
    "    discount = self._discount\n",
    "    if self._layout[new_y, new_x] == self._wall:  # a wall\n",
    "      reward = -1\n",
    "      new_state = (y, x)\n",
    "    elif self._layout[new_y, new_x] == self._key: # a key\n",
    "      reward = 10\n",
    "      item = 'KEY'\n",
    "      #print(item, ' we found a key')\n",
    "    elif self._layout[new_y, new_x] == self._door: # a door\n",
    "      reward = 5\n",
    "      #print(agent_inventory, ' inventory at the door')\n",
    "      if 'KEY' not in agent_inventory:\n",
    "        reward = -1\n",
    "        # What is going on here?\n",
    "        #  - Perhaps the replaybuffer?dist\n",
    "        #  - Perhaps it is the plotting that is fucking up\n",
    "        #  - We have states, never visited.\n",
    "        # we have a hole\n",
    "        new_state = (y, x)\n",
    "    elif self._layout[new_y, new_x] > 0: # a goal\n",
    "      reward = self._layout[new_y, new_x]\n",
    "\n",
    "      discount = 0.\n",
    "      new_state = self._start_state\n",
    "    else:\n",
    "      #reward = float((new_y + new_x)) / float(np.sum(self._layout.shape))\n",
    "      reward = 0\n",
    "    if self._noisy:\n",
    "      width = self._layout.shape[1]\n",
    "      reward += 2*np.random.normal(0, width - new_x + new_y)\n",
    "    \n",
    "    self._state = new_state\n",
    "\n",
    "    return reward, discount, self.get_obs(), item\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hallway(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUsYSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84acc11c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM0QLOEO0gDO/AegV7MW90QS3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84acc44590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCC3gDKEFnCG0gDOEFnDmfxUkAwB3W+mLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84aca98c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACEhJREFUeJzt3FFolNkZxvHn3URpyhC2G1HTkpWi0C4iaoUaobaJeOGF\nWLqJCEVYasreyEZEUYoXhYUqIjRUClrElL2qVrchakELemOhpUuUEqQXRaEJsuiajYliSZr19CKJ\nDDLJGGe+Oef9/P9AyEzyzjkzycM5znfesRCCAPjxVuwJAFgYQgs4Q2gBZwgt4AyhBZwhtIAzhDYH\nzOwHZvaveb7/ezP7uJZzQnYIbQ6EEP4aQnivkscws/fM7DMz+9LMRszsL2ZW0WMiG4TWOTOrq9JD\n3ZfUEUJ4R9ISSZclnavSY6OKCG2izOx7ZnbLzMbM7I9mds7MPjazH5nZsJkdMrPPJfXO3ldUu97M\nBmZqz0n6WrnxQgjjIYShmZt1kp5LWpnJk0NFCG2CzGyRpD9J6pX0jqQ/SPpJ0Y8sl/S2pHclfThz\nXyiq7ZP0yUztBUkdCxh7VNIzSb+R9KtKngeyUR97AiipVVJdCOG3M7f7zOwfRd//StIvQwj/kyQz\nK67dJKk+hHBy5vanZvbZqw4cQviGmTVI+kDSULmfR+0R2jR9U9P/xyw2XPT1F7OBLaG5RO1/FjJ4\nCOG/ZvY7SV+Y2XdDCI8WUo9ssT1O0+eSvvXSfS1FX8/XmlWq9t3XmEOdpK+XeCxERmjT9DdJX5nZ\nXjOrM7MfS/p+0fdtjrrZ2ikz+8jM6s3s/ZdqSzKzrWa2zszeMrNGSb+W9KWkOa//Ig5Cm6CZre/7\nkn4uaVTSTzV9CWZi9kdeofZnkkYk7ZT06SsM+7am3/B6LOnfkr4taVsIYfL1ngWyYjTB+2Bmf5d0\nKoTwSey5IC5W2kSZ2Q/NbNnM9vgDSWskXY09L8RHaNP1HUn/1PT2eL+mTys9qOQBzewXZvbEzMZf\n+vfnakwYtcH2GHCGlRZwZt7DFWbGMgxEEkIoeWmv7ImohVyVnz3zlnVNLceiht9RrWuK60pheww4\nQ2gBZwgt4AyhBZwhtIAzhBZwhtACzhBawBlCCzhDaAFn5u3y4ewxEM9cZ49ZaQFnMmkYWEiP7uxn\n9i60r/d16mZrUjwknreaSsfK+m8o5b+f4rpSWGkBZwgt4AyhBZwhtIAzhBZwhtACzhBawBlCCzhD\naAFnCC3gDA0DQKJoGABygoaBMlI+lJ9yTaVj0TAwN1ZawJmyKy3g0ZMnT3Tw4EE9fPhQq1atUqFQ\n0OPHj9XT0xN7ahVjpUUubd++XZOTk+rr69OJEye0bNkyjY2NxZ5WVRBa5M7169d18+ZNdXV1vbhv\n9+7dWrx4ccRZVQ+hRe7cunVLZqbm5uYX9xUKBZ0+fTrirKqH0CK3Fi1aFHsKmSC0yJ0NGzZIkkZG\nRjQ+Pq79+/erra1NO3bs0J07dyLPrnKEFrmzZcsWtbW16ezZs2psbFRPT4/u3bunJUuWaPXq1bGn\nVzFCi1zq7+/XxMSEOjs7deDAAe3atUtNTU2xp1UVXKdFLhUKBZ05cyb2NDLBSgs4Q5cPkCi6fICc\noMunjJQ7aVKuqXQsunzmxkoLOENoAWcILeAMoQWcIbSAM4QWcIbQAs4QWsAZQgs4Q2gBZ2gYABJF\nwwCQE5k0DGR9QFyq/SFxavgd0TAA4LUQWsAZQgs4Q2gBZwgt4AyhBZwhtIAzhBZwhtACzhBawBka\nBoBE0TAA5IT7hoGUP73+TZ5b8VgpH/6nYQBA5ggt4AyhBZwhtIAzhBZwhtACzhBawBlCCzhDaAFn\nCC3gDA0DQKJoGABywn3DQMoHy9/kmlqORcMAgKQRWiStt7dXLS0tWr9+vfbt26fNmzeru7tbz58/\nj14TS9k3otgeUxN7e9ze3q41a9bo5MmTmpqaUmtrq3bu3KnDhw9HqanV9pg3opAL9fX16uzs1KlT\np5KrqRVCC3eWLl2q4eFhPXv2LLmaWiC0cGd2mzo1NZVcTS0QWrjz6NEjLV++XI2NjcnV1AKhhSuT\nk5O6ePGi9u7dm1xNrZQ9XAHE1Nvbq7t372psbEzd3d26ffu2Nm7c+OId3Zg1sXDJh5pMamo5Vl5P\nRM11yYeGASBRXKcFciKThoHUt1612vKn+NrFOPSe8uuQ+mtXCist4AyhBZwhtIAzhBZwhtACzhBa\nwBlCCzhDaAFnCC3gDKEFnKFhAEgUDQNATtAwUAYNAzQMvFxDwwCABSG0gDOEFnCG0ALOEFrAGUIL\nOENoAWcILeAMoQWcIbSAMzQMAImiYQDICRoGysjrofesXzcpv68dDQMAFoTQAs4QWsAZQgs4Q2gB\nZwgt4AyhBZwhtIAzhBZwhtACztAwACSKhgEgJzJpGEj90+tpGEi/YeBNrimuK4WVFnCG0ALOEFrA\nGUILOENoAWcILeAMoQWcIbSAM4QWcIbQAs4QWsAZunyARNHlA+QEXT4Z1qTcsUOXT7o1xXWllA0t\nfJmYmNCePXu0YsUKPX36VA0NDTp+/HjsaaGK2B7nTH9/v5qbm3X06FF1dXVpdHQ09pRQZYQ2Z4aG\nhnTjxg3dv39fa9eu1bZt22JPCVVGaHNm69atGhwcVEtLizZt2qTW1tbYU0KVEdqcWbduna5du6aO\njg4NDg7qyJEjsaeEKiO0OXPlyhW1t7frwoULOn/+vAYGBmJPCVVGaHNmYGBAV69elSQ1NTVp5cqV\nkWeEauOST840NDTo0qVLunz5sh48eKBjx47FnhKqjNDmzKFDh2JPARljeww4Q8MAkCgaBoCcoGGA\nmkxqajlW3mqK60phpQWcIbSAM4QWcIbQAs4QWsAZQgs4Q2gBZwgt4AyhBZwhtIAzhBZwhi4fIFFz\ndfnMG1oA6WF7DDhDaAFnCC3gDKEFnCG0gDP/B0d2BRSxXqXMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84ac960150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzE/85V4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84ac8744d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tasks = []\n",
    "tasks.append(Hallway(goal_loc = [(8,2,5), (2,2,5), (2,13,5), (8,13,5)], discount=0.98))\n",
    "tasks.append(Hallway(goal_loc = [(8, 2, 5)], discount=0.98))\n",
    "tasks.append(Hallway(goal_loc = [(2, 2, 5)], discount=0.98))\n",
    "tasks.append(Hallway(goal_loc = [(2, 13, 5)], discount=0.98))\n",
    "tasks.append(Hallway(goal_loc = [(8, 13, 5)], discount=0.98))\n",
    "for idt,task in enumerate(tasks):\n",
    "  task.plot_grid(title=\"grid_{}\".format(idt) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKfA7ifHvO-M"
   },
   "source": [
    "\n",
    "## Implement agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneralQ(object):\n",
    "\n",
    "  def __init__(self, number_of_states, number_of_actions, initial_state, target_policy, behaviour_policy, double, num_offline_updates=30, step_size=0.1):\n",
    "    self._q = np.zeros((number_of_states, number_of_actions))\n",
    "    self._replayBuffer_A = []\n",
    "    if double:\n",
    "      self._q2 = np.zeros((number_of_states, number_of_actions))\n",
    "      self._replayBuffer_B = []\n",
    "    self._s = initial_state\n",
    "    self._initial_state = initial_state\n",
    "    self._number_of_actions = number_of_actions\n",
    "    self._step_size = step_size\n",
    "    self._behaviour_policy = behaviour_policy\n",
    "    self._target_policy = target_policy\n",
    "    self._double = double\n",
    "    self._num_offline_updates = num_offline_updates\n",
    "    self._last_action = 0\n",
    "    self._inventory = set()\n",
    "  \n",
    "  def resetReplayBuffer(self):\n",
    "    self._replayBuffer_A = []\n",
    "    if self._double:\n",
    "      self._replayBuffer_B = []\n",
    "      \n",
    "  @property\n",
    "  def q_values(self):\n",
    "    if self._double:\n",
    "      return (self._q + self._q2)/2\n",
    "    else:\n",
    "      return self._q\n",
    "    \n",
    "  def resetState(self):\n",
    "    self._s = self._initial_state \n",
    "\n",
    "  def step(self, r, g, s, item, train):\n",
    "    td = None\n",
    "    \n",
    "    if item != None and train == True:\n",
    "      self._inventory.add(item)\n",
    "      \n",
    "    if self._double:\n",
    "      next_action = self._behaviour_policy(self.q_values[s,:], train)\n",
    "      if np.random.random() <= 0.5:\n",
    "        expectation = np.sum(self._target_policy(self._q[s,:], next_action) * self._q2[s,:])\n",
    "        td = self._step_size*(r + g*expectation - self._q[self._s,self._last_action])\n",
    "        if train == True:\n",
    "          self._q[self._s,self._last_action] += self._step_size*(r + g*expectation - self._q[self._s,self._last_action])\n",
    "          #self._q[self._s,self._last_action] += self._step_size*(r + g*self._q2[s,np.argmax(target_policy(self._q[s,:], next_action))] - self._q[self._s,self._last_action])\n",
    "          self._replayBuffer_A.append([self._s,self._last_action,r,g,s,next_action])\n",
    "\n",
    "          for _ in range(self._num_offline_updates):\n",
    "            replay = self._replayBuffer_A[np.random.randint(len(self._replayBuffer_A))]\n",
    "            expectation = np.sum(self._target_policy(self._q[replay[4],:], replay[5]) * self._q2[replay[4],:])\n",
    "            self._q[replay[0],replay[1]] += self._step_size*(replay[2] + replay[3] * expectation - self._q[replay[0],replay[1]])\n",
    "\n",
    "      else:\n",
    "        expectation = np.sum(self._target_policy(self._q2[s,:], next_action) * self._q[s,:])\n",
    "        td = self._step_size*(r + g*expectation - self._q2[self._s,self._last_action])\n",
    "        if train == True:\n",
    "          self._q2[self._s,self._last_action] += self._step_size*(r + g*expectation - self._q2[self._s,self._last_action])   \n",
    "          #self._q2[self._s,self._last_action] += self._step_size*(r + g*self._q[s,np.argmax(target_policy(self._q2[s,:], next_action))] - self._q2[self._s,self._last_action])    \n",
    "          self._replayBuffer_B.append([self._s,self._last_action,r,g,s,next_action])\n",
    "\n",
    "          for _ in range(self._num_offline_updates):\n",
    "            replay = self._replayBuffer_B[np.random.randint(len(self._replayBuffer_B))]\n",
    "            expectation = np.sum(self._target_policy(self._q[replay[4],:], replay[5]) * self._q2[replay[4],:])\n",
    "            self._q[replay[0],replay[1]] += self._step_size*(replay[2] + replay[3] * expectation - self._q[replay[0],replay[1]])\n",
    "\n",
    "      self._s = s\n",
    "      self._last_action = next_action\n",
    "      return self._last_action, self._inventory, td\n",
    "    else:\n",
    "      next_action = self._behaviour_policy(self._q[s,:], train)\n",
    "      # This is expected sarsa, but still functions as expected.\n",
    "      expectation = np.sum(self._target_policy(self._q[s,:], next_action) * self._q[s,:])\n",
    "      td = self._step_size*(r + g*expectation - self._q[self._s,self._last_action])\n",
    "      if train == True:\n",
    "        self._q[self._s,self._last_action] += self._step_size*(r + g*expectation - self._q[self._s,self._last_action])\n",
    "        #self._q[self._s,self._last_action] += self._step_size*(r + g*self._q[s,np.argmax(target_policy(self._q[s,:], next_action))] - self._q[self._s,self._last_action])\n",
    "        self._replayBuffer_A.append([self._s,self._last_action,r,g,s,next_action])\n",
    "\n",
    "        for _ in range(self._num_offline_updates):\n",
    "          replay = self._replayBuffer_A[np.random.randint(len(self._replayBuffer_A))]\n",
    "          expectation = np.sum(self._target_policy(self._q[replay[4],:], replay[5]) * self._q2[replay[4],:])\n",
    "          self._q[replay[0],replay[1]] += self._step_size*(replay[2] + replay[3] * expectation - self._q[replay[0],replay[1]])\n",
    "\n",
    "      self._s = s\n",
    "      self._last_action = next_action\n",
    "      #print(self._inventory)\n",
    "      return self._last_action, self._inventory, td\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_target_policy(q, a):\n",
    "  return np.eye(len(q))[np.argmax(q)]\n",
    "\n",
    "def SARSA_target_policy(q, a):\n",
    "  return np.eye(len(q))[a]\n",
    "\n",
    "def gen_behaviour_policy(q, train):\n",
    "  return epsilon_greedy(q, 0.1) if train == True else np.random.choice(np.where(np.max(q) == q)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMr_z0RZsHNj"
   },
   "source": [
    "An agent that uses **Neural-Sarsa/DQN** to learn action values.  The agent should expect a nxn input which it should flatten into a vector, and then pass through a multi-layer perceptron with a single hidden layer with 100 hidden nodes and ReLU activations.  Each weight layer should also have a bias.  Initialize all weights uniformly randomly in $[-0.05, 0.05]$.\n",
    "\n",
    "```\n",
    "NeuralSarsa(number_of_features=(2*vision_size + 1)**2,\n",
    "            number_of_hidden=100,\n",
    "            number_of_actions=4,\n",
    "            initial_state=grid.get_obs(),\n",
    "            step_size=0.01)\n",
    "            \n",
    "DQN(number_of_features=(2*vision_size + 1)**2,\n",
    "            number_of_hidden=100,\n",
    "            number_of_actions=4,\n",
    "            initial_state=grid.get_obs(),\n",
    "            step_size=0.01)\n",
    "```\n",
    "\n",
    "The number `vision_size` will be either 1 or 2 below.  The input vector will be of size $(2v + 1)^2$, which will correspond to a square local view of the grid, centered on the agent, and of size $(2v + 1) \\times (2v + 1)$ (so either 3x3 or 5x5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEURAL_CONTROLLER_DRIVER(object):\n",
    "  \n",
    "  # Target Network is the same, as C-step is just C=1\n",
    "  \n",
    "  def __init__(self, number_of_features_controller,\n",
    "                number_of_features_driver,\n",
    "                number_of_hidden_controller,\n",
    "                number_of_hidden_driver,\n",
    "                number_of_actions_controller,\n",
    "                number_of_actions_driver,\n",
    "                initial_state_controller,\n",
    "                initial_state_driver, \n",
    "                rl_alg_controller='DQN',\n",
    "                rl_alg_driver='DQN', \n",
    "                num_offline_updates_controller=5, \n",
    "                num_offline_updates_driver=5,\n",
    "                step_size_controller=0.01,\n",
    "                step_size_driver=0.01): \n",
    "    # HMMM?\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    self._prev_action_driver = 0\n",
    "    self._step_driver = step_size_driver\n",
    "    self._num_features_driver = number_of_features_driver\n",
    "    self._num_action_driver = number_of_actions_driver\n",
    "    self._num_hidden_driver = number_of_hidden_driver\n",
    "    self._initial_state_driver = initial_state_driver\n",
    "    self._s_driver = initial_state_driver\n",
    "    self._s_driver = np.reshape(self._s_driver, (1,-1))\n",
    "    self._times_trained_driver = 0\n",
    "    self._inventory = set()\n",
    "    self._replayBuffer_driver = []\n",
    "    self._num_offline_updates_driver = num_offline_updates_driver\n",
    "    self._rl_alg_driver = rl_alg_driver\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    self._prev_action_controller = 0\n",
    "    self._step_controller = step_size_controller\n",
    "    self._num_features_controller = number_of_features_controller\n",
    "    self._num_action_controller = number_of_actions_controller\n",
    "    self._num_hidden_controller = number_of_hidden_controller\n",
    "    self._initial_state_controller = initial_state_controller\n",
    "    self._s_controller = initial_state_controller\n",
    "    self._s_controller = np.reshape(self._s_controller, (1,-1))\n",
    "    self._times_trained_controller = 0\n",
    "    self._replayBuffer_controller = []\n",
    "    self._num_offline_updates_controller = num_offline_updates_controller\n",
    "    self._rl_alg_controller = rl_alg_controller\n",
    "    self.name = 'HYPER '+self._rl_alg_controller\n",
    "\n",
    "    # ?????????? should it be the number of tasks\n",
    "    self._probs_controller = np.ones((1, self._num_features_controller))/(self._num_features_controller*1.)\n",
    "    \n",
    "    self.handleTF()\n",
    "  \n",
    "  def reset(self):\n",
    "    tf.reset_default_graph()\n",
    "    self.handleTF()\n",
    "    self.resetState_controller()\n",
    "    self.resetReplayBuffer_controller()\n",
    "    self._probs_controller = np.ones((1, self._num_features_controller))/(self._num_features_controller*1.)\n",
    "    self._times_trained_controller = 0\n",
    "    self._prev_action_controller = 0\n",
    "    self.resetReplayBuffer()\n",
    "    self.resetState()\n",
    "    self._times_trained_driver = 0\n",
    "    self._prev_action_driver = 0\n",
    "    self._inventory = set()\n",
    "\n",
    "  def resetReplayBuffer_controller(self):\n",
    "    self._replayBuffer_controller = []\n",
    "    \n",
    "  def resetState_controller(self):\n",
    "    self._s_controller = self._initial_state_controller \n",
    "    self._s_controller = np.reshape(self._s_controller, (1,-1))\n",
    "    \n",
    "  def handleTF(self):\n",
    "    self._sess = tf.Session()\n",
    "    #tf.reset_default_graph()\n",
    "    self.rewTensor_controller = tf.placeholder(tf.float64)\n",
    "    self.disTensor_controller = tf.placeholder(tf.float64)\n",
    "    self.nqTensor_controller = tf.placeholder(tf.float64)\n",
    "    self.actionTensor_controller = tf.placeholder(tf.int32)\n",
    "    self.stateTensor_controller = tf.placeholder(tf.float64, shape=(1,self._num_features_controller))\n",
    "    self._dense_1_controller = tf.layers.dense(self.stateTensor_controller,\n",
    "                                    self._num_hidden_controller, activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.random_uniform_initializer(-0.05, 0.05),\n",
    "                                    bias_initializer=tf.random_uniform_initializer(-0.05, 0.05))\n",
    "    self._dense_2_controller = tf.layers.dense(self._dense_1_controller,\n",
    "                                    self._num_action_controller, activation=None,\n",
    "                                    kernel_initializer=tf.random_uniform_initializer(-0.05, 0.05),\n",
    "                                    bias_initializer=tf.random_uniform_initializer(-0.05, 0.05))\n",
    "    self._q_controller = tf.reshape(self._dense_2_controller, (self._num_action_controller,))    \n",
    "    self._softmx_controller = tf.nn.softmax(self._q_controller)\n",
    "    self._cost_controller = tf.losses.mean_squared_error(self.rewTensor_controller + self.disTensor_controller*self.nqTensor_controller, self._q_controller[self.actionTensor_controller])\n",
    "    self._opt_controller = tf.train.GradientDescentOptimizer(self._step_controller).minimize(self._cost_controller) \n",
    "    \n",
    "\n",
    "    self.rewTensor_driver = tf.placeholder(tf.float64)\n",
    "    self.disTensor_driver = tf.placeholder(tf.float64)\n",
    "    self.nqTensor_driver = tf.placeholder(tf.float64)\n",
    "    self.actionTensor_driver = tf.placeholder(tf.int32)\n",
    "    self.stateTensor_driver = tf.placeholder(tf.float64, shape=(1,self._num_features_driver))\n",
    "    self._dense_1_driver = tf.layers.dense(self.stateTensor_driver,\n",
    "                                    self._num_hidden_driver, activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.random_uniform_initializer(-0.05, 0.05),\n",
    "                                    bias_initializer=tf.random_uniform_initializer(-0.05, 0.05))\n",
    "    self._dense_2_driver = tf.layers.dense(self._dense_1_driver,\n",
    "                                    self._num_action_driver, activation=None,\n",
    "                                    kernel_initializer=tf.random_uniform_initializer(-0.05, 0.05),\n",
    "                                    bias_initializer=tf.random_uniform_initializer(-0.05, 0.05))\n",
    "    self._q_driver = tf.reshape(self._dense_2_driver, (self._num_action_driver,))    \n",
    "    self._cost_driver = tf.losses.mean_squared_error(self.rewTensor_driver+ self.disTensor_driver*self.nqTensor_driver, self._q_driver[self.actionTensor_driver])\n",
    "    self._opt_driver = tf.train.GradientDescentOptimizer(self._step_driver).minimize(self._cost_driver)\n",
    "\n",
    "\n",
    "    # HMMM?\n",
    "    self._sess.run(tf.global_variables_initializer())\n",
    "\n",
    "  def _target_policy_controller(self, q, a):\n",
    "    return np.eye(len(q))[a]\n",
    " \n",
    "  def _behaviour_policy_controller(self, q):    \n",
    "    return epsilon_greedy(q, 0.1)# if train == True else np.random.choice(np.where(np.max(q) == q)[0])\n",
    "\n",
    "  def getProbs(self):\n",
    "    # softmax\n",
    "    return self._probs_controller\n",
    "\n",
    "  def q_controller(self, obs):\n",
    "    #print [n.name for n in tf.get_default_graph().as_graph_def().node]\n",
    "    obs = np.reshape(obs,(1,-1))\n",
    "    #print obs\n",
    "    t, probs = self._sess.run([self._q_controller, self._softmx_controller], {self.stateTensor_controller: obs})\n",
    "    return t, probs\n",
    "  \n",
    "  def step_controller(self, r, g, s):\n",
    "    qvs, probs = self.q_controller(s)\n",
    "    q_nxtState = np.reshape(qvs, (-1,))\n",
    "    self._probs_controller = probs\n",
    "    next_action = self._behaviour_policy_controller(q_nxtState)\n",
    "    \n",
    "    if r != None:\n",
    "      if self._rl_alg_controller == 'NEURALSARSA':\n",
    "        target = self._target_policy_controller(q_nxtState, next_action)\n",
    "        target = np.random.choice(np.where(np.max(target) == target)[0])\n",
    "        vob = q_nxtState[target]\n",
    "        #print vob\n",
    "        self._sess.run(self._opt_controller,{\n",
    "            self.nqTensor_controller: vob,\n",
    "            self.rewTensor_controller: r,\n",
    "            self.disTensor_controller: g,\n",
    "            self.actionTensor_controller: self._prev_action_controller,\n",
    "            self.stateTensor_controller: self._s_controller})\n",
    "        self._replayBuffer_controller.append([self._s_controller, self._prev_action_controller, r, g, vob])\n",
    "        for _ in range(self._num_offline_updates_controller):\n",
    "          replay = self._replayBuffer_controller[np.random.randint(len(self._replayBuffer_controller))]\n",
    "          self._sess.run(self._opt_controller,{\n",
    "              self.nqTensor_controller: replay[4],\n",
    "              self.rewTensor_controller: replay[2],\n",
    "              self.disTensor_controller: replay[3],\n",
    "              self.actionTensor_controller: replay[1],\n",
    "              self.stateTensor_controller: replay[0]})\n",
    "      elif self._rl_alg_controller == 'DQN':\n",
    "        # This function should return an action\n",
    "        # Optimiser\n",
    "        vob = np.max(q_nxtState)\n",
    "        self._sess.run(self._opt_controller,{\n",
    "            self.nqTensor_controller: vob,\n",
    "            self.rewTensor_controller: r,\n",
    "            self.disTensor_controller: g,\n",
    "            self.actionTensor_controller: self._prev_action_controller,\n",
    "            self.stateTensor_controller: self._s_controller})\n",
    "        self._replayBuffer_controller.append([self._s_controller, self._prev_action_controller, r, g, vob])\n",
    "        for _ in range(self._num_offline_updates_controller):\n",
    "          replay = self._replayBuffer_controller[np.random.randint(len(self._replayBuffer_controller))]\n",
    "          self._sess.run(self._opt_controller,{\n",
    "              self.nqTensor_controller: replay[4],\n",
    "              self.rewTensor_controller: replay[2],\n",
    "              self.disTensor_controller: replay[3],\n",
    "              self.actionTensor_controller: replay[1],\n",
    "              self.stateTensor_controller: replay[0]})\n",
    "\n",
    "    self._s_controller = np.reshape(s, (1,-1))\n",
    "    self._prev_action_controller = next_action\n",
    "    return next_action\n",
    "\n",
    "  def reset_controller(self):\n",
    "    tf.reset_default_graph()\n",
    "    self.handleTF()\n",
    "    self.resetState_controller()\n",
    "    self.resetReplayBuffer_controller()\n",
    "    self._probs_controller = np.ones((1, self._num_features_controller))/(self._num_features_controller*1.)\n",
    "    self._times_trained_controller = 0\n",
    "    self._prev_action_controller = 0\n",
    "\n",
    "\n",
    "\n",
    "    # resetReplayBuffer_driver\n",
    "  def resetReplayBuffer(self):\n",
    "    self._replayBuffer_driver = []\n",
    "    \n",
    "    # resetState_driver\n",
    "  def resetState(self):\n",
    "    self._s_driver = self._initial_state_driver \n",
    "    self._s_driver = np.reshape(self._s_driver, (1,-1))\n",
    "\n",
    "\n",
    "  def _target_policy_driver(self, q, a):\n",
    "    return np.eye(len(q))[a]\n",
    " \n",
    "  def _behaviour_policy_driver(self, q, train):    \n",
    "    return epsilon_greedy(q, 0.1) if train == True else np.random.choice(np.where(np.max(q) == q)[0])\n",
    "\n",
    "  def q_driver(self, obs):\n",
    "    #print [n.name for n in tf.get_default_graph().as_graph_def().node]\n",
    "    obs = np.reshape(obs,(1,-1))\n",
    "    #print obs\n",
    "    t = self._sess.run(self._q_driver, {self.stateTensor_driver: obs})\n",
    "    return t\n",
    "  \n",
    "  # step_driver\n",
    "  def step(self, r, g, s, item, train):\n",
    "    cost = None\n",
    "    \n",
    "    if item != None and train == True:\n",
    "      self._inventory.add(item)\n",
    "    \n",
    "    # This function should return an action\n",
    "    q_nxtState = np.reshape(self.q_driver(s), (-1,))\n",
    "    next_action = self._behaviour_policy_driver(q_nxtState, train)\n",
    "    \n",
    "\n",
    "    if self._rl_alg_driver == 'NEURALSARSA':\n",
    "      target = self._target_policy_driver(q_nxtState, next_action)\n",
    "      target = np.random.choice(np.where(np.max(target) == target)[0])\n",
    "      \n",
    "      # Optimiser\n",
    "      vob = q_nxtState[target]\n",
    "#       cost = self._sess.run(self._cost_driver,{\n",
    "#           self.nqTensor_driver: vob,\n",
    "#           self.rewTensor_driver: r,\n",
    "#           self.disTensor_driver: g,\n",
    "#           self.actionTensor_driver: self._prev_action_driver,\n",
    "#           self.stateTensor_driver: self._s_driver})\n",
    "      if train == True:\n",
    "        self._sess.run(self._opt_driver,{\n",
    "            self.nqTensor_driver: vob,\n",
    "            self.rewTensor_driver: r,\n",
    "            self.disTensor_driver: g,\n",
    "            self.actionTensor_driver: self._prev_action_driver,\n",
    "            self.stateTensor_driver: self._s_driver})\n",
    "        self._replayBuffer_driver.append([self._s_driver, self._prev_action_driver, r, g, vob])\n",
    "        for _ in range(self._num_offline_updates_driver):\n",
    "          replay = self._replayBuffer_driver[np.random.randint(len(self._replayBuffer_driver))]\n",
    "          self._sess.run(self._opt_driver,{\n",
    "              self.nqTensor_driver: replay[4],\n",
    "              self.rewTensor_driver: replay[2],\n",
    "              self.disTensor_driver: replay[3],\n",
    "              self.actionTensor_driver: replay[1],\n",
    "              self.stateTensor_driver: replay[0]})\n",
    "    elif self._rl_alg_driver == 'DQN':\n",
    "      vob = np.max(q_nxtState)\n",
    "#       cost = self._sess.run(self._cost_driver,{\n",
    "#               self.nqTensor_driver: vob,\n",
    "#               self.rewTensor_driver: r,\n",
    "#               self.disTensor_driver: g,\n",
    "#               self.actionTensor_driver: self._prev_action_driver,\n",
    "#               self.stateTensor_driver: self._s_driver})\n",
    "      if train == True:\n",
    "        self._sess.run(self._opt_driver,{\n",
    "            self.nqTensor_driver: vob,\n",
    "            self.rewTensor_driver: r,\n",
    "            self.disTensor_driver: g,\n",
    "            self.actionTensor_driver: self._prev_action_driver,\n",
    "            self.stateTensor_driver: self._s_driver})\n",
    "        self._replayBuffer_driver.append([self._s_driver, self._prev_action_driver, r, g, vob])\n",
    "        for _ in range(self._num_offline_updates_driver):\n",
    "          replay = self._replayBuffer_driver[np.random.randint(len(self._replayBuffer_driver))]\n",
    "          self._sess.run(self._opt_driver,{\n",
    "              self.nqTensor_driver: replay[4],\n",
    "              self.rewTensor_driver: replay[2],\n",
    "              self.disTensor_driver: replay[3],\n",
    "              self.actionTensor_driver: replay[1],\n",
    "              self.stateTensor_driver: replay[0]})\n",
    "\n",
    "    \n",
    "        \n",
    "    self._s_driver = np.reshape(s, (1,-1))\n",
    "    self._prev_action_driver = next_action\n",
    "    return next_action, self._inventory, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 0: Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random(object):\n",
    "  \"\"\"A random agent.\n",
    "  \n",
    "  This agent returns an action between 0 and 'number_of_arms', \n",
    "  uniformly at random. The 'previous_action' argument of 'step'\n",
    "  is ignored.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, number_of_arms):\n",
    "    self._number_of_arms = number_of_arms\n",
    "    self.name = 'random'\n",
    "    self.reset()\n",
    "\n",
    "  def step(self, previous_action, reward):\n",
    "    return np.random.randint(self._number_of_arms)\n",
    "  \n",
    "  def getProbs(self):\n",
    "    return np.ones((self._number_of_arms))/self._number_of_arms\n",
    "  \n",
    "  def reset(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Agent 1: REINFORCE agents\n",
    "Implementation of REINFORCE policy-gradient methods\n",
    "\n",
    "The policy should be a softmax on action preferences:\n",
    "$$\\pi(a) = \\frac{\\exp(p(a))}{\\sum_b \\exp(p(b))}\\,.$$\n",
    "\n",
    "The action preferences are stored separately, so that for each action $a$ the preference $p(a)$ is a single value that you directly update.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class REINFORCE(object):\n",
    " \n",
    "  def __init__(self, number_of_arms, step_size=0.1, baseline=False):\n",
    "    self._number_of_arms = number_of_arms\n",
    "    self._lr = step_size\n",
    "    self.name = 'reinforce, baseline: {}'.format(baseline)\n",
    "    self._baseline = baseline\n",
    "    self.action_values = np.zeros((2,self._number_of_arms))\n",
    "    self.action_preferences = np.zeros((1,self._number_of_arms))\n",
    "    self.total_reward = 0;\n",
    "    self.number_rewards = 0.\n",
    "    self.reset()\n",
    "  \n",
    "  def step(self, previous_action, reward):\n",
    "    if previous_action != None:\n",
    "      self.number_rewards += 1.\n",
    "      self.total_reward += reward\n",
    "      self.action_values[0,previous_action] += reward\n",
    "      self.action_values[1,previous_action] += 1.\n",
    "      self.updatePreferences(previous_action, reward)\n",
    "#    unvisited = np.where(self.action_values[1,:] == 0.)\n",
    "#     if unvisited[0].size > 0:\n",
    "#       return unvisited[0][0]\n",
    "#     else:\n",
    "#       return np.random.choice(np.arange(0,self._number_of_arms),p=self.softmax())\n",
    "    return np.random.choice(np.arange(0,self._number_of_arms),p=self.softmax())\n",
    "    \n",
    "  def reset(self):\n",
    "    self.action_values = np.zeros((2,self._number_of_arms))\n",
    "    self.action_preferences = np.zeros((1,self._number_of_arms))\n",
    "    self.number_rewards = 0.\n",
    "    self.total_reward = 0.\n",
    "  \n",
    "  def updatePreferences(self, previous_action, reward):\n",
    "    if not self._baseline: \n",
    "      self.action_preferences[0,previous_action]+=self._lr*reward*(1-self.softmax()[previous_action])\n",
    "      for i in range(0,self._number_of_arms):\n",
    "        if i != previous_action:\n",
    "          self.action_preferences[0,i]-=self._lr*reward*self.softmax()[i]\n",
    "    else:\n",
    "      self.action_preferences[0,previous_action]+=self._lr*(reward - self.total_reward/self.number_rewards)*(1-self.softmax()[previous_action])\n",
    "      for i in range(0,self._number_of_arms):\n",
    "        if i != previous_action:\n",
    "          self.action_preferences[0,i]-=self._lr*(reward - self.total_reward/self.number_rewards)*self.softmax()[i]\n",
    "    \n",
    "  def softmax(self):\n",
    "    q = np.sum(np.exp(self.action_preferences),axis=1)\n",
    "    t = np.exp(self.action_preferences)/q\n",
    "    return t.flatten()\n",
    "  \n",
    "  def getProbs(self):\n",
    "    return self.softmax()\n",
    "  \n",
    "  \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 2: EXP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXP3(object):\n",
    "\n",
    "  def __init__(self, number_of_arms, gamma):\n",
    "    self._number_of_arms = number_of_arms\n",
    "    self.name = 'exp3 Gamma: ' + str(gamma)\n",
    "    \n",
    "    self.action_values = np.zeros((2,self._number_of_arms))\n",
    "    \n",
    "    self.gamma = gamma\n",
    "    self.weights = np.ones((1,self._number_of_arms))\n",
    "    \n",
    "    self.time = 0.\n",
    "    self.reset()\n",
    "  \n",
    "  def step(self, previous_action, reward):\n",
    "    if previous_action != None:\n",
    "      xhat = np.zeros((1, self._number_of_arms))\n",
    "      xhat[0,previous_action] = reward/self.action_values[0,previous_action]\n",
    "      self.weights = self.weights*np.exp(self.gamma*xhat/self._number_of_arms)\n",
    "      self.action_values[1,previous_action] += 1.\n",
    "    self.action_values[0,:] = (1-self.gamma)*(self.weights)/(np.sum(self.weights)) + self.gamma/self._number_of_arms\n",
    "    action = np.random.choice(self._number_of_arms, p=self.action_values[0,:])\n",
    "    self.time += 1.\n",
    "    unvisited = np.where(self.action_values[1,:] == 0.)\n",
    "    return unvisited[0][0] if unvisited[0].size > 0 else action\n",
    "  \n",
    "  def getProbs(self):\n",
    "    return self.action_values[0,:]\n",
    "  \n",
    "  def reset(self):\n",
    "    self.action_values = np.zeros((2, self._number_of_arms))\n",
    "    self.weights = np.ones((1, self._number_of_arms))\n",
    "    self.time = 0\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 3: EXP3.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXP3S(object):\n",
    "\n",
    "  def __init__(self, number_of_arms, gamma, alpha):\n",
    "    self._number_of_arms = number_of_arms\n",
    "    self.name = 'exp3s Gamma: ' + str(gamma) + ', Alpha: ' + str(alpha) \n",
    "    \n",
    "    self.action_values = np.zeros((2,number_of_arms))\n",
    "    \n",
    "    self.gamma = gamma\n",
    "    self.alpha = alpha\n",
    "    self.weights = np.ones((1,number_of_arms))\n",
    "    \n",
    "    self.time = 0.\n",
    "    self.reset()\n",
    "  \n",
    "  def step(self, previous_action, reward):\n",
    "    if previous_action != None:\n",
    "      xhat = np.zeros((1, self._number_of_arms))\n",
    "      xhat[0,previous_action] = reward/self.action_values[0,previous_action]\n",
    "      # Should the added term be using updated weights as we move across arms, or simultaenous updates?\n",
    "      #print 'test'\n",
    "      self.weights = self.weights*np.exp(self.gamma*xhat/self._number_of_arms) + ((np.e*self.alpha)/(self._number_of_arms))*np.sum(self.weights)\n",
    "      self.action_values[1,previous_action] += 1.\n",
    "    self.action_values[0,:] = (1-self.gamma)*(self.weights)/(np.sum(self.weights)) + self.gamma/self._number_of_arms\n",
    "    action = np.random.choice(self._number_of_arms, p=self.action_values[0,:])\n",
    "    self.time += 1.\n",
    "    unvisited = np.where(self.action_values[1,:] == 0.)\n",
    "    return unvisited[0][0] if unvisited[0].size > 0 else action\n",
    "  \n",
    "  def getProbs(self):\n",
    "    return self.action_values[0,:]\n",
    "  \n",
    "  def reset(self):\n",
    "    self.action_values = np.zeros((2, self._number_of_arms))\n",
    "    self.weights = np.ones((1, self._number_of_arms))\n",
    "    self.time = 0\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 4: StrategicBandit with EXP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 5: StrategicBandit with EXP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 6: NeuralBandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs to Net are reward signal or reward_signal, and inventory\n",
    "# Outputs are probabilities of arms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 7: Task Selection via RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NS_DQN(object):\n",
    "  \n",
    "  # Target Network is the same, as C-step is just C=1\n",
    "  \n",
    "  def __init__(self, teacher_student, number_of_features, number_of_hidden, number_of_actions, initial_state, rl_alg='DQN', num_offline_updates=30, step_size=0.01):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    self._prev_action = 0\n",
    "    self._step = step_size\n",
    "    self._num_features = number_of_features\n",
    "    self._num_action = number_of_actions\n",
    "    self._num_hidden = number_of_hidden\n",
    "    self._initial_state = initial_state\n",
    "    self._s = initial_state\n",
    "    self._s = np.reshape(self._s, (1,-1))\n",
    "    self._times_trained = 0\n",
    "    self._replayBuffer = []\n",
    "    self._num_offline_updates = num_offline_updates\n",
    "    self._rl_alg = rl_alg\n",
    "    self._teacher_student = teacher_student\n",
    "    self._probs = np.ones((1, self._num_action))/(self._num_action*1.)\n",
    "    self._inventory = set()\n",
    "    \n",
    "    if self._teacher_student == True:\n",
    "      self.name = 'HYPER '+self._rl_alg\n",
    "    else:\n",
    "      self.name = self._rl_alg\n",
    "    \n",
    "    self.handleTF()\n",
    "  \n",
    "  def resetReplayBuffer(self):\n",
    "    self._replayBuffer = []\n",
    "    \n",
    "  def resetState(self):\n",
    "    self._s = self._initial_state \n",
    "    self._s = np.reshape(self._s, (1,-1))\n",
    "    \n",
    "  def handleTF(self):\n",
    "    self._sess = tf.Session()\n",
    "    #tf.reset_default_graph()\n",
    "    self.rewTensor = tf.placeholder(tf.float64)\n",
    "    self.disTensor = tf.placeholder(tf.float64)\n",
    "    self.nqTensor = tf.placeholder(tf.float64)\n",
    "    self.actionTensor = tf.placeholder(tf.int32)\n",
    "    self.stateTensor = tf.placeholder(tf.float64, shape=(1,self._num_features))\n",
    "    self._dense_1 = tf.layers.dense(self.stateTensor,\n",
    "                                    self._num_hidden, activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.random_uniform_initializer(-0.05, 0.05),\n",
    "                                    bias_initializer=tf.random_uniform_initializer(-0.05, 0.05))\n",
    "    self._dense_2 = tf.layers.dense(self._dense_1,\n",
    "                                    self._num_action, activation=None,\n",
    "                                    kernel_initializer=tf.random_uniform_initializer(-0.05, 0.05),\n",
    "                                    bias_initializer=tf.random_uniform_initializer(-0.05, 0.05))\n",
    "    self._q = tf.reshape(self._dense_2, (self._num_action,))    \n",
    "    self._softmx = tf.nn.softmax(self._q)\n",
    "    self._cost = tf.losses.mean_squared_error(self.rewTensor + self.disTensor*self.nqTensor, self._q[self.actionTensor])\n",
    "    self._opt = tf.train.GradientDescentOptimizer(self._step).minimize(self._cost) \n",
    "    # HMMM?\n",
    "    self._sess.run(tf.global_variables_initializer())\n",
    "\n",
    "  def _target_policy(self, q, a):\n",
    "    return np.eye(len(q))[a]\n",
    " \n",
    "  def _behaviour_policy(self, q, train):\n",
    "    if self._teacher_student == True:   \n",
    "      return epsilon_greedy(q, 0.1)#if train == True else np.random.choice(np.where(np.max(q) == q)[0])\n",
    "    else:\n",
    "      return epsilon_greedy(q, 0.1) if train == True else np.random.choice(np.where(np.max(q) == q)[0])\n",
    "  \n",
    "  def getProbs(self):\n",
    "    # softmax\n",
    "    return self._probs\n",
    "  \n",
    "  def q_noProbs(self, obs):\n",
    "    obs = np.reshape(obs,(1,-1))\n",
    "    t = self._sess.run(self._q, {self.stateTensor: obs})\n",
    "    return t\n",
    "  \n",
    "  def q(self, obs):\n",
    "    obs = np.reshape(obs,(1,-1))\n",
    "    t, probs = self._sess.run([self._q, self._softmx], {self.stateTensor: obs})\n",
    "    return t, probs\n",
    "  \n",
    "  def step(self, r, g, s, item, train):\n",
    "    cost = None\n",
    "\n",
    "    if item != None and train == True:\n",
    "      self._inventory.add(item)\n",
    "\n",
    "    qvs, probs = self.q(s)\n",
    "    q_nxtState = np.reshape(qvs, (-1,))\n",
    "    self._probs = probs\n",
    "    next_action = self._behaviour_policy(q_nxtState, train)\n",
    "    \n",
    "    if r != None:\n",
    "      if self._rl_alg == 'NEURALSARSA':\n",
    "        target = self._target_policy(q_nxtState, next_action)\n",
    "        target = np.random.choice(np.where(np.max(target) == target)[0])\n",
    "        vob = q_nxtState[target]\n",
    "\n",
    "        if train == True:\n",
    "          self._sess.run(self._opt,{\n",
    "              self.nqTensor: vob,\n",
    "              self.rewTensor: r,\n",
    "              self.disTensor: g,\n",
    "              self.actionTensor: self._prev_action,\n",
    "              self.stateTensor: self._s})\n",
    "          self._replayBuffer.append([self._s, self._prev_action, r, g, vob])\n",
    "          for _ in range(self._num_offline_updates):\n",
    "            replay = self._replayBuffer[np.random.randint(len(self._replayBuffer))]\n",
    "            self._sess.run(self._opt,{\n",
    "                self.nqTensor: replay[4],\n",
    "                self.rewTensor: replay[2],\n",
    "                self.disTensor: replay[3],\n",
    "                self.actionTensor: replay[1],\n",
    "                self.stateTensor: replay[0]})\n",
    "      elif self._rl_alg == 'DQN':\n",
    "        vob = np.max(q_nxtState)\n",
    "\n",
    "        if train == True:\n",
    "          self._sess.run(self._opt,{\n",
    "              self.nqTensor: vob,\n",
    "              self.rewTensor: r,\n",
    "              self.disTensor: g,\n",
    "              self.actionTensor: self._prev_action,\n",
    "              self.stateTensor: self._s})\n",
    "          self._replayBuffer.append([self._s, self._prev_action, r, g, vob])\n",
    "          for _ in range(self._num_offline_updates):\n",
    "            replay = self._replayBuffer[np.random.randint(len(self._replayBuffer))]\n",
    "            self._sess.run(self._opt,{\n",
    "                self.nqTensor: replay[4],\n",
    "                self.rewTensor: replay[2],\n",
    "                self.disTensor: replay[3],\n",
    "                self.actionTensor: replay[1],\n",
    "                self.stateTensor: replay[0]})\n",
    "\n",
    "    self._s = np.reshape(s, (1,-1))\n",
    "    self._prev_action = next_action\n",
    "    return next_action, self._inventory, cost\n",
    "\n",
    "  def reset(self):\n",
    "    tf.reset_default_graph()\n",
    "    self.handleTF()\n",
    "    self.resetState()\n",
    "    self.resetReplayBuffer()\n",
    "    self._probs = np.ones((1, self._num_action))/(self._num_action*1.)\n",
    "    self._times_trained = 0\n",
    "    self._prev_action = 0\n",
    "    self._inventory = set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskSelector(object):\n",
    "  \"\"\"An adversarial multi-armed Task bandit.\"\"\"\n",
    "  \n",
    "  def __init__(self, rl_agent, tasks, reward_signal):\n",
    "    self._unscaled_reward_history = []\n",
    "    self._rl_agent = rl_agent\n",
    "    self._tasks = tasks\n",
    "    self._reward_signal = reward_signal\n",
    "    self._tasks_buffer = np.zeros((5,len(tasks)))\n",
    "  \n",
    "  def resetReplayBuffer(self):\n",
    "    self._rl_agent.resetReplayBuffer()    \n",
    "  \n",
    "  def step(self, action_task_id):\n",
    "    if self._reward_signal == 'PG':\n",
    "      run_step(self._tasks[action_task_id], self._rl_agent, True)\n",
    "      reward_after, reward_steps_after = run_step(self._tasks[action_task_id], self._rl_agent, False)\n",
    "    elif self._reward_signal == 'GPG':\n",
    "      pass\n",
    "    elif self._reward_signal == 'SPG':\n",
    "      run_step(self._tasks[action_task_id], self._rl_agent, True)\n",
    "      reward_after, reward_steps_after = run_step(self._tasks[action_task_id], self._rl_agent, False)\n",
    "    elif self._reward_signal == 'TPG':\n",
    "      run_step(self._tasks[action_task_id], self._rl_agent, True)\n",
    "      reward_after, reward_steps_after = run_step(self._tasks[-1], self._rl_agent, False)\n",
    "    elif self._reward_signal == 'MPG':\n",
    "      uniform_sampled_task_id = np.random.choice(len(self._tasks))\n",
    "      run_step(self._tasks[action_task_id], self._rl_agent, True)\n",
    "      reward_after, reward_steps_after = run_step(self._tasks[uniform_sampled_task_id], self._rl_agent, False)\n",
    "    elif self._reward_signal == 'VCG':\n",
    "      pass\n",
    "    elif self._reward_signal == 'GVCG':\n",
    "      pass\n",
    "    elif self._reward_signal == 'L2G':\n",
    "      pass      \n",
    "    \n",
    "    self._tasks_buffer[:,action_task_id] = np.roll(self._tasks_buffer[:,action_task_id], 1)\n",
    "    self._tasks_buffer[0,action_task_id] = reward_steps_after\n",
    "    X = np.arange(self._tasks_buffer.shape[0])\n",
    "    slope, _, _, _, _ = stats.linregress(X, self._tasks_buffer[:,action_task_id])\n",
    "    rhat = slope \n",
    "    \n",
    "    self._unscaled_reward_history.append(rhat)\n",
    "    temp_history = np.array(sorted(self._unscaled_reward_history))\n",
    "    p_20 = np.percentile(temp_history, 20)\n",
    "    p_80 = np.percentile(temp_history, 80)        \n",
    "\n",
    "    if action_task_id < 0 or action_task_id >= len(self._tasks):\n",
    "      raise ValueError('Action {} is out of bounds for a '\n",
    "                       '{}-armed bandit'.format(action_task_id, len(split_train_tasks)))\n",
    "    \n",
    "    r = None\n",
    "    if rhat <= p_20:\n",
    "      r = -1.\n",
    "    elif rhat > p_80:\n",
    "      r = 1.\n",
    "    else:\n",
    "      r = 2.0 * (rhat - p_20)/(p_80 - p_20) - 1.\n",
    "    \n",
    "    print reward_steps_after\n",
    "    # Perhaps, plot the variance or something else, because the train==False fucks this plot up\n",
    "    return r, reward_steps_after, np.reshape(self._tasks_buffer.T,(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_values(values, colormap='pink', vmin=None, vmax=None):\n",
    "  plt.imshow(values, interpolation=\"nearest\", cmap=colormap, vmin=vmin, vmax=vmax)\n",
    "  plt.yticks([])\n",
    "  plt.xticks([])\n",
    "  plt.colorbar(ticks=[vmin, vmax])\n",
    "\n",
    "def plot_action_values(action_values, title, vmin=None, vmax=None):\n",
    "  q = action_values\n",
    "  fig = plt.figure(figsize=(10, 10))\n",
    "  fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "  vmin = np.min(action_values)\n",
    "  vmax = np.max(action_values)\n",
    "  #print vmin, vmax\n",
    "  dif = vmax - vmin\n",
    "  for a in [0, 1, 2, 3]:\n",
    "    plt.subplot(3, 3, map_from_action_to_subplot(a))\n",
    "    plot_values(q[..., a], vmin=vmin - 0.05*dif, vmax=vmax + 0.05*dif)\n",
    "    action_name = map_from_action_to_name(a)\n",
    "    plt.title(r\"$q(s, \\mathrm{\" + action_name + r\"})$\")\n",
    "    \n",
    "  plt.subplot(3, 3, 5)\n",
    "  v = 0.9 * np.max(q, axis=-1) + 0.1 * np.mean(q, axis=-1)\n",
    "  plot_values(v, colormap='summer', vmin=vmin, vmax=vmax)\n",
    "  plt.title(r\"$v(s), \\mathrm{\" + title + r\"}$\")\n",
    "#   plt.savefig('./action_values_{}'.format(title))\n",
    "#   plt.close()\n",
    "\n",
    "def plot_greedy_policy(grid, title, q):\n",
    "  action_names = [r\"$\\uparrow$\",r\"$\\rightarrow$\", r\"$\\downarrow$\", r\"$\\leftarrow$\"]\n",
    "  greedy_actions = np.argmax(q, axis=2)\n",
    "  grid.plot_grid(title)\n",
    "  plt.hold('on')\n",
    "  for i in range(grid._layout.shape[0]):\n",
    "    for j in range(grid._layout.shape[1]):\n",
    "      action_name = action_names[greedy_actions[i,j]]\n",
    "      plt.text(j, i, action_name, ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(bandit, algs, tasks, number_of_steps_of_selecting_tasks, repetitions, vision_size, tabular, agent_type_driver, hidden_units, step_size, reward_signal):\n",
    "  \"\"\"Run multiple repetitions of a bandit experiment.\"\"\"\n",
    "  reward_dict = {}\n",
    "  reward_delta_dict = {}\n",
    "  action_dict = {}\n",
    "  prob_dict = {}\n",
    "  entropy_dict = {}\n",
    "  \n",
    "  for alg in algs:\n",
    "    print('Running:', alg.name)\n",
    "    reward_dict[alg.name] = []\n",
    "    reward_delta_dict[alg.name] = []\n",
    "    action_dict[alg.name] = []\n",
    "    prob_dict[alg.name] = []\n",
    "    entropy_dict[alg.name] = []\n",
    "    \n",
    "    rl_agent = None\n",
    "    qs = None\n",
    "    \n",
    "    for qq in range(repetitions):\n",
    "      print('Rep:', qq)\n",
    "      \n",
    "      if (agent_type_driver == 'NEURALSARSA' or agent_type_driver == 'DQN') and ('HYPER' in alg.name):\n",
    "        alg.reset()\n",
    "        bandit = TaskSelector(alg, tasks, reward_signal)\n",
    "\n",
    "        reward_dict[alg.name].append([0.])\n",
    "        reward_delta_dict[alg.name].append([])\n",
    "        action_dict[alg.name].append([])\n",
    "        prob_dict[alg.name].append([])\n",
    "        entropy_dict[alg.name].append([])\n",
    "        action = None\n",
    "        reward = None\n",
    "        prob = None\n",
    "        entropy = None\n",
    "        reward_delta = None\n",
    "        capability = alg._initial_state_controller\n",
    "        \n",
    "        for i in range(number_of_steps_of_selecting_tasks):\n",
    "          try:\n",
    "            action = alg.step_controller(reward, 0.98, capability)\n",
    "            prob = alg.getProbs()\n",
    "            entropy = -1.0 * np.sum(prob * np.log(prob))\n",
    "          except:\n",
    "              raise ValueError(\n",
    "                \"The step function of algorithm `{}` failed.\\\n",
    "                Perhaps you have a bug, such as a typo.\\\n",
    "                Or, perhaps your value estimates or policy has diverged.\\\n",
    "                (E.g., internal quantities may have become NaNs.)\\\n",
    "                Try adding print statements to see if you can find a bug.\".format(alg.name))\n",
    "          reward, reward_from_environment, capability = bandit.step(action)\n",
    "          bandit.resetReplayBuffer()\n",
    "          reward_dict[alg.name][-1].append(reward_from_environment+reward_dict[alg.name][-1][-1])\n",
    "          reward_delta_dict[alg.name][-1].append(reward)\n",
    "          action_dict[alg.name][-1].append(action)\n",
    "          prob_dict[alg.name][-1].append(prob.copy())\n",
    "          entropy_dict[alg.name][-1].append(entropy)\n",
    "        \n",
    "        h, w = tasks[-1]._layout.shape\n",
    "        obs = np.array([[tasks[-1].get_obs_at(x, y) for x in range(2, w-2)] for y in range(2, h-2)])\n",
    "        if qs is not None:\n",
    "          qs += np.array([[[alg.q_driver(o)[a] for a in range(4)] if o[vision_size,vision_size] == 0 else np.zeros((4,)) for o in ob] for ob in obs])\n",
    "        else:\n",
    "          qs = np.array([[[alg.q_driver(o)[a] for a in range(4)] if o[vision_size,vision_size] == 0 else np.zeros((4,)) for o in ob] for ob in obs])\n",
    "\n",
    "      else:\n",
    "        alg.reset()\n",
    "        rl_agent = None\n",
    "        \n",
    "        if agent_type_driver == 'NEURALSARSA' or agent_type_driver == 'DQN':\n",
    "          rl_agent = NS_DQN(teacher_student=False,\n",
    "                      number_of_features=(2*vision_size + 1)**2,\n",
    "                      number_of_hidden=hidden_units,\n",
    "                      number_of_actions=4,\n",
    "                      initial_state=tasks[0].get_obs(),\n",
    "                      rl_alg=agent_type_driver,\n",
    "                      step_size=step_size)\n",
    "        elif agent_type_driver == 'Q':\n",
    "          rl_agent = GeneralQ(number_of_states=tasks[0]._layout.size,\n",
    "                  number_of_actions=4,\n",
    "                  initial_state=tasks[0].get_obs(),\n",
    "                  target_policy=Q_target_policy,\n",
    "                  behaviour_policy=gen_behaviour_policy,\n",
    "                  double=True)\n",
    "        elif agent_type_driver == 'SARSA':\n",
    "          rl_agent = GeneralQ(number_of_states=tasks[0]._layout.size,\n",
    "                  number_of_actions=4,\n",
    "                  initial_state=tasks[0].get_obs(),\n",
    "                  target_policy=SARSA_target_policy,\n",
    "                  behaviour_policy=gen_behaviour_policy,\n",
    "                  double=True)\n",
    "        \n",
    "        bandit = TaskSelector(rl_agent, tasks, reward_signal)\n",
    "        \n",
    "        reward_dict[alg.name].append([0.])\n",
    "        reward_delta_dict[alg.name].append([])\n",
    "        action_dict[alg.name].append([])\n",
    "        prob_dict[alg.name].append([])\n",
    "        entropy_dict[alg.name].append([])\n",
    "        action = None\n",
    "        reward = None\n",
    "        prob = None\n",
    "        entropy = None\n",
    "        reward_delta = None\n",
    "        capability = None\n",
    "        if 'HYPER' in alg.name: \n",
    "          capability = alg._initial_state\n",
    "        \n",
    "        for i in range(number_of_steps_of_selecting_tasks):\n",
    "          try:\n",
    "            if 'HYPER' in alg.name:\n",
    "              action = alg.step(reward, 0.98, capability)\n",
    "            else:\n",
    "              action = alg.step(action, reward)\n",
    "            prob = alg.getProbs()\n",
    "            entropy = -1.*np.sum(prob*np.log(prob))\n",
    "          except:\n",
    "              raise ValueError(\n",
    "                \"The step function of algorithm `{}` failed.\\\n",
    "                Perhaps you have a bug, such as a typo.\\\n",
    "                Or, perhaps your value estimates or policy has diverged.\\\n",
    "                (E.g., internal quantities may have become NaNs.)\\\n",
    "                Try adding print statements to see if you can find a bug.\".format(alg.name))\n",
    "          reward, reward_from_environment, capability = bandit.step(action)\n",
    "          print reward_from_environment\n",
    "          bandit.resetReplayBuffer()\n",
    "          \n",
    "          reward_dict[alg.name][-1].append(reward_from_environment+reward_dict[alg.name][-1][-1])\n",
    "          print reward_dict[alg.name][-1]\n",
    "          reward_delta_dict[alg.name][-1].append(reward)\n",
    "          action_dict[alg.name][-1].append(action)\n",
    "          prob_dict[alg.name][-1].append(prob.copy())\n",
    "          entropy_dict[alg.name][-1].append(entropy)\n",
    "          \n",
    "        if agent_type_driver == 'NEURALSARSA' or agent_type_driver == 'DQN':\n",
    "          h, w = tasks[-1]._layout.shape\n",
    "          obs = np.array([[tasks[-1].get_obs_at(x, y) for x in range(2, w-2)] for y in range(2, h-2)])\n",
    "          if qs is not None:\n",
    "            qs += np.array([[[rl_agent.q_noProbs(o)[a] for a in range(4)] if o[vision_size,vision_size] == 0 else np.zeros((4,)) for o in ob] for ob in obs])\n",
    "          else:\n",
    "            qs = np.array([[[rl_agent.q_noProbs(o)[a] for a in range(4)] if o[vision_size,vision_size] == 0 else np.zeros((4,)) for o in ob] for ob in obs])\n",
    "        elif agent_type_driver == 'Q' or agent_type_driver == 'SARSA':\n",
    "          if qs is not None:\n",
    "            qs += rl_agent.q_values.reshape(tasks[-1]._layout.shape + (4,))\n",
    "          else:\n",
    "            qs = rl_agent.q_values.reshape(tasks[-1]._layout.shape + (4,))\n",
    "      #print('')      \n",
    "    \n",
    "    qs /= repetitions\n",
    "    plot_action_values(qs, alg.name)\n",
    "        \n",
    "  return reward_dict, reward_delta_dict, action_dict, prob_dict, entropy_dict\n",
    "\n",
    "def train_task_agents(agents, number_of_arms, number_of_steps_of_selecting_tasks, tasks, reward_signal, repetitions=1, vision_size=1, tabular=False, agent_type_driver='norm', hidden_units=100, step_size=0.01):\n",
    "  bandit = None\n",
    "  reward_dict, reward_delta_dict, action_dict, prob_dict, entropy_dict = run_experiment(bandit, agents, tasks, number_of_steps_of_selecting_tasks, repetitions, vision_size, tabular, agent_type_driver, hidden_units, step_size, reward_signal)\n",
    "  \n",
    "  smoothed_rewards = {}\n",
    "  smoothed_reward_deltas = {}\n",
    "  smoothed_actions = {}\n",
    "  smoothed_probs = {}\n",
    "  smoothed_entropies = {}\n",
    "  \n",
    "  agent_set = set()\n",
    "  \n",
    "  for agent, rewards in reward_dict.items():\n",
    "    agent_set.add(agent)\n",
    "    smoothed_rewards[agent] = (np.sum(np.array([np.array(x) for x in rewards]), axis=0)).T\n",
    "  \n",
    "  for agent, rewards in reward_delta_dict.items():\n",
    "    agent_set.add(agent)\n",
    "    smoothed_reward_deltas[agent] = (np.sum(np.array([np.array(x) for x in rewards]), axis=0)).T\n",
    "\n",
    "  \n",
    "  for agent, probs in prob_dict.items():\n",
    "    smoothed_probs[agent] = (np.sum(np.array([np.array(x) for x in probs]), axis=0)).T\n",
    "\n",
    "  for agent, entropies in entropy_dict.items():\n",
    "    smoothed_entropies[agent] = (np.sum(np.array([np.array(x) for x in entropies]), axis=0)).T\n",
    "  \n",
    "  for agent in agent_set:\n",
    "    smoothed_probs[agent] /= repetitions\n",
    "    \n",
    "    plt.figure(figsize=(22,20))\n",
    "    plt.imshow(smoothed_probs[agent], interpolation=None)\n",
    "    plt.title('Teacher: {}, Student: {}, Reward Signal: {}'.format(agent, agent_type_driver, reward_signal))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Task')\n",
    "#     plt.savefig('./'+agent + ', Reward Signal: {}; {}'.format(reward_signal, agent_type_driver_driver))\n",
    "#     plt.close()\n",
    "  \n",
    "  plt.figure(figsize=(12,12))\n",
    "  plt.title('Cumulative Average Reward, Student: {}, Reward Signal: {}'.format(agent_type_driver, reward_signal))\n",
    "  plt.ylabel('Reward')\n",
    "  plt.xlabel('Time')\n",
    "  for agent in agent_set:\n",
    "    smoothed_rewards[agent] /= repetitions    \n",
    "    plt.plot(smoothed_rewards[agent], label=agent)\n",
    "  plt.legend(loc='upper right')\n",
    "#   plt.savefig('./Average Reward, \\t Reward Signal: {}; {}'.format(reward_signal, agent_type_driver))\n",
    "#   plt.close()\n",
    "  \n",
    "  plt.figure(figsize=(12,12))\n",
    "  plt.title('Delta Average Reward, Student: {}, Reward Signal: {}'.format(agent_type_driver, reward_signal))\n",
    "  plt.ylabel('Delta')\n",
    "  plt.xlabel('Time')\n",
    "  for agent in agent_set:\n",
    "    smoothed_reward_deltas[agent] /= repetitions    \n",
    "    plt.plot(smoothed_reward_deltas[agent], label=agent)\n",
    "  plt.legend(loc='upper right')\n",
    "#   plt.savefig('./Delta Reward, \\t Reward Signal: {}; {}'.format(reward_signal, agent_type_driver))\n",
    "#   plt.close()\n",
    "  \n",
    "  plt.figure(figsize=(12,12))\n",
    "  plt.title('Entropy, Teacher: {}, Reward Signal: {}'.format(agent_type_driver, reward_signal))\n",
    "  plt.ylabel('Policy Entropy')\n",
    "  plt.xlabel('Time')\n",
    "  for agent in agent_set:\n",
    "    smoothed_entropies[agent] /= repetitions  \n",
    "    plt.plot(smoothed_entropies[agent], label=agent)\n",
    "  plt.legend(loc='upper right')\n",
    "#   plt.savefig('./Maximum Likelihood, \\t Reward Signal: {}; {}'.format(reward_signal, agent_type_driver))\n",
    "#   plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_step(env, agent, train):     \n",
    "    env.resetState()\n",
    "    agent.resetState()\n",
    "    number_of_steps = env.distanceToGoal()\n",
    "    try:\n",
    "      action = agent.initial_action()\n",
    "      agent_inventory = agent._inventory\n",
    "    except AttributeError:\n",
    "      action = 0\n",
    "      agent_inventory = agent._inventory\n",
    "    steps_completed = 0\n",
    "    total_reward = 0.\n",
    "    while steps_completed != number_of_steps:\n",
    "      reward, discount, next_state, item = env.step(action, agent_inventory)\n",
    "      total_reward += reward\n",
    "      print reward, discount, next_state, item\n",
    "      \n",
    "      if reward == 100:\n",
    "        agent._inventory.remove('KEY')\n",
    "      \n",
    "      if discount == 0:\n",
    "        return total_reward, total_reward/steps_completed\n",
    "      action, agent_inventory, _ = agent.step(reward, discount, next_state, item, train)\n",
    "      steps_completed += 1\n",
    "    \n",
    "    mean_reward = total_reward/number_of_steps\n",
    "\n",
    "    return total_reward, mean_reward\n",
    "  \n",
    "def run_episode(env, agent, number_of_episodes, train):\n",
    "    # Mean Reward across all the episodes( aka all steps )\n",
    "    mean_reward = 0.\n",
    "    \n",
    "    # Mean Duration per episode\n",
    "    mean_duration = 0.\n",
    "    \n",
    "    # List of (Total Reward Per Epsiode)/(Duration)\n",
    "    signal_per_episode = np.zeros((1, number_of_episodes))\n",
    "    reward_per_episode = np.zeros((1, number_of_episodes))\n",
    "    duration_per_episode = np.zeros((1, number_of_episodes))\n",
    "    \n",
    "    try:\n",
    "      action = agent.initial_action()\n",
    "    except AttributeError:\n",
    "      action = 0\n",
    "    \n",
    "    episodes_completed = 0\n",
    "    total_reward_per_episode = 0.\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    i = 0.\n",
    "    while episodes_completed != number_of_episodes:\n",
    "      reward, discount, next_state = env.step(action)\n",
    "      total_reward_per_episode += reward\n",
    "      \n",
    "      if discount == 0:\n",
    "        duration = time.time() - start_time\n",
    "        signal_per_episode[0,episodes_completed] = (total_reward_per_episode/duration)\n",
    "        reward_per_episode[0,episodes_completed] = (total_reward_per_episode)\n",
    "        duration_per_episode[0,episodes_completed] = (duration)\n",
    "        \n",
    "        episodes_completed += 1\n",
    "        mean_duration += (duration - mean_duration)/(episodes_completed)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        total_reward_per_episode = 0.\n",
    "        \n",
    "      action = agent.step(reward, discount, next_state, train)\n",
    "      mean_reward += (reward - mean_reward)/(i + 1.)\n",
    "      i += 1.\n",
    "    \n",
    "    mean_signal = np.mean(signal_per_episode)\n",
    "    total_reward = np.sum(reward_per_episode)\n",
    "    total_duration = np.sum(duration_per_episode)\n",
    "\n",
    "    return total_reward, total_duration\n",
    "\n",
    "map_from_action_to_subplot = lambda a: (2, 6, 8, 4)[a]\n",
    "map_from_action_to_name = lambda a: (\"up\", \"right\", \"down\", \"left\")[a]\n",
    "  \n",
    "def epsilon_greedy(q_values, epsilon):\n",
    "  if epsilon < np.random.random():\n",
    "    return np.argmax(q_values)\n",
    "  else:\n",
    "    return np.random.randint(np.array(q_values).shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward as Reward Signal for Bandit(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralRL/Bandit Controllers with Neural RL Agents\n",
    "#### NeuralRL Controller state input is the buffered reward across all tasks within 5 timesteps\n",
    "#### NeuralRL Controller does not have inventory as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_steps_of_selecting_tasks = 10\n",
    "reps = 1\n",
    "reward_signals=['SPG']\n",
    "drivers = ['NEURALSARSA','DQN']\n",
    "hidden_units_controller_net = 10\n",
    "hidden_units_driver_net = 20\n",
    "#hidden_units_driver_net = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Running:', 'random')\n",
      "('Rep:', 0)\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "5 0.0 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0.0\n",
      "0.0\n",
      "[0.0, 0.0]\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "5 0.0 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "5 0.0 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0.384615384615\n",
      "0.384615384615\n",
      "[0.0, 0.0, 0.38461538461538464]\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "5 0.0 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "5 0.0 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0.384615384615\n",
      "0.384615384615\n",
      "[0.0, 0.0, 0.38461538461538464, 0.7692307692307693]\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [1 1 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "5 0.0 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0.0\n",
      "0.0\n",
      "[0.0, 0.0, 0.38461538461538464, 0.7692307692307693, 0.7692307692307693]\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0.0\n",
      "0.0\n",
      "[0.0, 0.0, 0.38461538461538464, 0.7692307692307693, 0.7692307692307693, 0.7692307692307693]\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0.0\n",
      "0.0\n",
      "[0.0, 0.0, 0.38461538461538464, 0.7692307692307693, 0.7692307692307693, 0.7692307692307693, 0.7692307692307693]\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5c9d73ed7070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                       \u001b[0mtabular_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                       \u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                       hidden_units_driver_net)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-d0ff3480134e>\u001b[0m in \u001b[0;36mtrain_task_agents\u001b[0;34m(agents, number_of_arms, number_of_steps_of_selecting_tasks, tasks, reward_signal, repetitions, vision_size, tabular, agent_type_driver, hidden_units, step_size)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_task_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_arms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_steps_of_selecting_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvision_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_type_driver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'norm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0mbandit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   \u001b[0mreward_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_delta_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_steps_of_selecting_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvision_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_type_driver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0msmoothed_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d0ff3480134e>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(bandit, algs, tasks, number_of_steps_of_selecting_tasks, repetitions, vision_size, tabular, agent_type_driver, hidden_units, step_size, reward_signal)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal\u001b[0m \u001b[0mquantities\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mbecome\u001b[0m \u001b[0mNaNs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 Try adding print statements to see if you can find a bug.\".format(alg.name))\n\u001b[0;32m--> 124\u001b[0;31m           \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_from_environment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbandit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m           \u001b[0;32mprint\u001b[0m \u001b[0mreward_from_environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m           \u001b[0mbandit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresetReplayBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-9fec3cab2971>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action_task_id)\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reward_signal\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SPG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction_task_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rl_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0mreward_after\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_steps_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction_task_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rl_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reward_signal\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'TPG'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-80f8feb3d1db>\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(env, agent, train)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdiscount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_reward\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msteps_completed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_inventory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0msteps_completed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-e6704a52f6a1>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, r, g, s, item, train)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactionTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreplay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                 self.stateTensor: replay[0]})\n\u001b[0m\u001b[1;32m    117\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rl_alg\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DQN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mvob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_nxtState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1105\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \"\"\"\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    269\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 271\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    272\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3034\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3035\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3053\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_tensor and allow_operation can't both be False.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3055\u001b[0;31m     \u001b[0mtemp_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_graph_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3056\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtemp_obj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3057\u001b[0m       \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_as_graph_element\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0motherwise\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m   \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m   \u001b[0mconv_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_as_graph_element\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconv_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconv_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84acc11bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vision_size = 1\n",
    "tabular_grid = False\n",
    "step_size = 0.01\n",
    "\n",
    "# goal_loc has format (row, col)\n",
    "tasks = []\n",
    "tasks.append(Hallway(goal_loc = [(8,2,-3), (2,2,5), (2,13,5), (8,13,100)], tabular=tabular_grid, vision_size=vision_size, discount=0.98))\n",
    "\n",
    "for task in tasks:\n",
    "  task.plot_grid()\n",
    "  \n",
    "# Intrinsically Motivated Curriculum Learning\n",
    "number_of_arms_tasks = len(tasks)\n",
    "\n",
    "agents = [\n",
    "      Random(number_of_arms_tasks),\n",
    "]\n",
    "\n",
    "for reward_signal in reward_signals:\n",
    "  for driver in drivers:\n",
    "    train_task_agents(agents,\n",
    "                      number_of_arms_tasks,\n",
    "                      number_of_steps_of_selecting_tasks, \n",
    "                      tasks,\n",
    "                      reward_signal,\n",
    "                      reps,\n",
    "                      vision_size,\n",
    "                      tabular_grid,\n",
    "                      driver,\n",
    "                      hidden_units_driver_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Running:', 'HYPER DQN')\n",
      "('Rep:', 0)\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [0 1 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[1 1 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "-1 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [1 1 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [1 1 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [1 1 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [1 1 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [1 1 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [1 1 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "-1 0.98 [[1 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [0 0 1]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]] None\n",
      "-1 0.98 [[0 1 0]\n",
      " [0 0 0]\n",
      " [1 1 0]] None\n",
      "0 0.98 [[0 0 1]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 1]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "-1 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 1 1]\n",
      " [0 0 0]\n",
      " [1 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [1 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[1 0 0]\n",
      " [0 0 0]\n",
      " [0 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [1 1 1]] None\n",
      "0 0.98 [[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]] None\n",
      "0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The step function of algorithm `HYPER DQN` failed.                Perhaps you have a bug, such as a typo.                Or, perhaps your value estimates or policy has diverged.                (E.g., internal quantities may have become NaNs.)                Try adding print statements to see if you can find a bug.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d026da551a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m                       \u001b[0mtabular_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                       \u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                       hidden_units_driver_net)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-d0ff3480134e>\u001b[0m in \u001b[0;36mtrain_task_agents\u001b[0;34m(agents, number_of_arms, number_of_steps_of_selecting_tasks, tasks, reward_signal, repetitions, vision_size, tabular, agent_type_driver, hidden_units, step_size)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_task_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_arms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_steps_of_selecting_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvision_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_type_driver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'norm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0mbandit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   \u001b[0mreward_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_delta_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_steps_of_selecting_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepetitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvision_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_type_driver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0msmoothed_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-d0ff3480134e>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(bandit, algs, tasks, number_of_steps_of_selecting_tasks, repetitions, vision_size, tabular, agent_type_driver, hidden_units, step_size, reward_signal)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mOr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperhaps\u001b[0m \u001b[0myour\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mestimates\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mdiverged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal\u001b[0m \u001b[0mquantities\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mbecome\u001b[0m \u001b[0mNaNs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 Try adding print statements to see if you can find a bug.\".format(alg.name))\n\u001b[0m\u001b[1;32m     51\u001b[0m           \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_from_environment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbandit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m           \u001b[0mbandit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresetReplayBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The step function of algorithm `HYPER DQN` failed.                Perhaps you have a bug, such as a typo.                Or, perhaps your value estimates or policy has diverged.                (E.g., internal quantities may have become NaNs.)                Try adding print statements to see if you can find a bug."
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84ac972390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIbRAMIQWCIbQAsH8H52IQmtxjQ3iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84aca4e210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEAyhBYIhtEAw/wegN0JrySmyBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84aca33a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO0AAADICAYAAAAELGYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBhCCwRDaIFg/g8iOEJrPW/EPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84a48a8c90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vision_size = 1\n",
    "tabular_grid = False\n",
    "step_size = 0.01\n",
    "\n",
    "# goal_loc has format (row, col)\n",
    "tasks = []\n",
    "tasks.append(Hallway(goal_loc = [(8, 2, -3)], tabular=tabular_grid, vision_size=vision_size, discount=0.98))\n",
    "tasks.append(Hallway(goal_loc = [(2, 2, 5)], tabular=tabular_grid, vision_size=vision_size, discount=0.98))\n",
    "tasks.append(Hallway(goal_loc = [(2, 13, 5)], tabular=tabular_grid, vision_size=vision_size,discount=0.98))\n",
    "tasks.append(Hallway(goal_loc = [(8, 13, 100)], tabular=tabular_grid, vision_size=vision_size, discount=0.98))\n",
    "\n",
    "for task in tasks:\n",
    "  task.plot_grid()\n",
    "  \n",
    "# Intrinsically Motivated Curriculum Learning\n",
    "number_of_arms_tasks = len(tasks)\n",
    "\n",
    "agents = [\n",
    "      NEURAL_CONTROLLER_DRIVER(number_of_arms_tasks,\n",
    "                              (2*vision_size + 1)**2,\n",
    "                              hidden_units_controller_net,\n",
    "                              hidden_units_driver_net,\n",
    "                              number_of_arms_tasks,\n",
    "                              4,\n",
    "                              np.zeros((1,number_of_arms_tasks)),\n",
    "                              tasks[0].get_obs(),\n",
    "                              'DQN',\n",
    "                              'DQN'),\n",
    "  NEURAL_CONTROLLER_DRIVER(number_of_arms_tasks,\n",
    "                              (2*vision_size + 1)**2,\n",
    "                              hidden_units_controller_net,\n",
    "                              hidden_units_driver_net,\n",
    "                              number_of_arms_tasks,\n",
    "                              4,\n",
    "                              np.zeros((1,number_of_arms_tasks)),\n",
    "                              tasks[0].get_obs(),\n",
    "                              'DQN',\n",
    "                              'NEURALSARSA'),\n",
    "    NEURAL_CONTROLLER_DRIVER(number_of_arms_tasks,\n",
    "                              (2*vision_size + 1)**2,\n",
    "                              hidden_units_controller_net,\n",
    "                              hidden_units_driver_net,\n",
    "                              number_of_arms_tasks,\n",
    "                              4,\n",
    "                              np.zeros((1,number_of_arms_tasks)),\n",
    "                              tasks[0].get_obs(),\n",
    "                              'NEURALSARSA',\n",
    "                              'NEURALSARSA'),\n",
    "  NEURAL_CONTROLLER_DRIVER(number_of_arms_tasks,\n",
    "                              (2*vision_size + 1)**2,\n",
    "                              hidden_units_controller_net,\n",
    "                              hidden_units_driver_net,\n",
    "                              number_of_arms_tasks,\n",
    "                              4,\n",
    "                              np.zeros((1,number_of_arms_tasks)),\n",
    "                              tasks[0].get_obs(),\n",
    "                              'NEURALSARSA',\n",
    "                              'DQN'),\n",
    "    Random(number_of_arms_tasks),\n",
    "]\n",
    "\n",
    "\n",
    "for reward_signal in reward_signals:\n",
    "  for driver in drivers:\n",
    "    train_task_agents(agents,\n",
    "                      number_of_arms_tasks,\n",
    "                      number_of_steps_of_selecting_tasks, \n",
    "                      tasks,\n",
    "                      reward_signal,\n",
    "                      reps,\n",
    "                      vision_size,\n",
    "                      tabular_grid,\n",
    "                      driver,\n",
    "                      hidden_units_driver_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "17045589_RL_hw4.ipynb",
   "provenance": [
    {
     "file_id": "1a1ONHRz5bcd2rJyLUD53OUMR8npSp0QZ",
     "timestamp": 1522325021849
    },
    {
     "file_id": "1Ldj742iIDtvjYKKwENvrpTQ3Hm2wrqIg",
     "timestamp": 1521476023411
    },
    {
     "file_id": "1FwMxkDPkt68fxovrMmmWwm6ohYvX2wt1",
     "timestamp": 1517660129183
    },
    {
     "file_id": "1wwTq5nociiMHUb26jxrvZvGN6l11xV5o",
     "timestamp": 1517174839485
    },
    {
     "file_id": "1_gJNoj9wG4mnigscGRAcZx7RHix3HCjG",
     "timestamp": 1515086437469
    },
    {
     "file_id": "1hcBeMVfaSh8g1R2ujtmxOSHoxJ8xYkaW",
     "timestamp": 1511098107887
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
